# -*- coding: utf-8 -*-
"""SMV_revised.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16xQedji8MDaqoDwE6RlCqqdxql4oAKSX

#1. Introduction
### In this notebook, we aim to predict SMV (Standard Minute Value) using a Random Forest Regressor model. We will load the dataset, clean the data, encode categorical variables, train the model, evaluate its performance, and analyze feature importance and residuals.

#2. Data Loading
### First, we load the dataset and preview the first few rows to understand its structure. We are using the pandas library to read the Excel file.
"""

# Load the dataset
import pandas as pd

data = pd.read_excel('/content/SMV-12&7GG.xlsx')  # Load dataset
print("First few rows of the dataset:")
print(data.head())  # Display the first few rows

"""#3. Data Cleaning
### The dataset might contain non-numeric or missing values (represented by '-'). We'll clean the data by replacing these non-numeric entries with NaN and filling missing values with 0.
"""

# Data Cleaning: Handle non-numeric entries in the dataset
data.replace('-', pd.NA, inplace=True)  # Replace '-' with NaN
data.fillna(0, inplace=True)  # Fill NaN values with 0
print("\nDataset after cleaning:")
print(data.info())  # Check the dataset after cleaning

"""#4. Encoding Categorical Variables
### Machine learning models require numerical input. We use one-hot encoding to convert categorical variables (like 'Operation', 'Yarn Type', etc.) into numeric form.
"""

# Encode Categorical Variables using One-Hot Encoding
data_encoded = pd.get_dummies(data, columns=['Operation', 'Operation Position',
                                             'Yarn Type', 'GG',
                                             'Operation Description', 'Knit Construction'])
print("\nFirst few rows after encoding categorical variables:")
print(data_encoded.head())  # Display first few rows of the encoded data

"""#5. Splitting the Data into Features and Target
### Next, we split the dataset into features (X) and the target variable (y). The target variable here is SMV, which we want to predict.
"""

# Prepare Feature Matrix (X) and Target Variable (y)
X = data_encoded.drop('SMV', axis=1)  # Features (everything except SMV)
y = data_encoded['SMV']  # Target (SMV)

"""#6. Train-Test Split
### We divide the data into training and testing sets. Typically, 80% of the data is used for training, and 20% is used for testing to evaluate the model’s performance.
"""

# Split Data into Training and Testing Sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("\nData split into training and test sets.")

"""#7. Training the Random Forest Regressor Model
### Now that our data is ready, we train a Random Forest Regressor model. This model will learn the relationship between the features and the target variable (SMV).
"""

# Train a Random Forest Regressor Model
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)  # Train the model
print("\nRandom Forest Model trained.")

"""#8. Saving the Trained Model
### We save the trained model to a file so it can be loaded and used later without retraining.
"""

# Save the Trained Model for Later Use
import joblib

joblib.dump(model, 'trained_model.pkl')  # Save the model to a file
print("\nTrained model saved.")

"""#9. Making Predictions on the Test Set
### After training, we make predictions on the test data (X_test) and compare them with the actual values (y_test).
"""

# Make Predictions on the Test Set
y_pred = model.predict(X_test)  # Predictions on the test set

"""#10. Model Evaluation
### We evaluate the performance of the model using metrics like Mean Squared Error (MSE) and R-squared (R²). These metrics help us understand how well the model is performing.
"""

# Evaluate Model Performance
from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"\nModel Performance:")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

"""#11. Saving Predictions to an Excel File
### We save the test data along with the actual and predicted SMV values to an Excel file for easy access and further analysis.
"""

# Save Predictions to an Excel File
X_test_with_categories = X_test.copy()  # Copy test features
X_test_with_categories['Actual SMV'] = y_test  # Add actual SMV
X_test_with_categories['Predicted SMV'] = y_pred  # Add predicted SMV

X_test_with_categories.to_excel('SMV_predictions_with_categories.xlsx', index=False)  # Save to Excel
print("\nPredictions saved to 'SMV_predictions_with_categories.xlsx'.")

# Download the Excel file (useful for Google Colab)
from google.colab import files
files.download('SMV_predictions_with_categories.xlsx')

"""#12. Feature Importance Analysis
### Random Forest provides a measure of feature importance, helping us understand which features had the most impact on the model’s predictions.
"""

# Feature Importance Analysis
import matplotlib.pyplot as plt
import numpy as np
importances = model.feature_importances_
feature_names = X.columns

# Create a DataFrame for feature importance
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# Plot Feature Importance
feature_importance_df.plot(kind='bar', x='Feature', y='Importance', legend=False)
plt.title('Feature Importance')
plt.show()

"""#13. Residual Analysis
### We analyze the residuals (difference between the actual and predicted values) to assess the model’s errors.
"""

# Residual Analysis
residuals = y_test - y_pred
print(f"\nResidual Analysis:")
print(f"Mean Residual: {np.mean(residuals)}")
print(f"Max Residual: {np.max(residuals)}")
print(f"Min Residual: {np.min(residuals)}")

# Plot Residuals vs Predicted SMV
plt.scatter(y_pred, residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted SMV')
plt.ylabel('Residuals')
plt.title('Residuals vs Predicted SMV')
plt.show()

